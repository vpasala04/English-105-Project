{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Pandas Package for Data Analysis, pt.1\n",
    "\n",
    "This notebook will walk us through a quick tutorial in using the pandas package for data anlysis with python.\n",
    "\n",
    "### Overview of Tutorial\n",
    "\n",
    "Over the next 2 class sessions, we will use this tutorial to cover the following processes:\n",
    "\n",
    "*Day 1*\n",
    "1. importing the pandas package \n",
    "2. creating a dataframe\n",
    "3. exploring our dataframe's attributes\n",
    "\n",
    "*Day 2*\n",
    "4. using functions to filter our data\n",
    "5. using functions to merge and join our data\n",
    "6. creating a subset and exporting as a new .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "This Pandas tutorial has been adapted from materials provided by the excellent staff at the Davis Library Research Hub.\n",
    "\n",
    "For more detailed examples and exericses, see thier [Python: Intro to Data lessons](https://unc-libraries-data.github.io/Python/Intro/Introduction_CrashCourse.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Pandas\n",
    "\n",
    "#### Packages\n",
    "Packages provide additional tools and functions not present in base Python. Python includes a number of packages to start with, the Anaconda distribution which we've all downloaded for Unit 3 comes with the \"Pandas\" package already installed.\n",
    "\n",
    "Once you've installed a package, you can load it into your current Python session with the import function. Otherwise these functions will not be available.\n",
    "\n",
    "\n",
    "#### Pandas\n",
    "\n",
    "Like spreadsheets in Microsoft Excel, Pandas allows us to store our data in tabular, multi-dimensional objects (dataframes) with familiar features like rows, columns, and headers. This is useful because it makes management, manipulation, and cleaning of large datasets much easier than would be the case using Python's built-in data structures such as lists. Pandas also provides a wide range of useful tools for working with data once it has been stored and structured.\n",
    "\n",
    "Begin by importing the pandas package using the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we load pandas with the usual `import pandas` and an extra `as pd` statement. This allows us to call functions from `pandas` with `pd.<function>` instead of `pandas.<function>` for convenience. `as pd` is **not** necessary to load the package.\n",
    "\n",
    "Note, we also imported the `numpy` package, which is going to help pandas do some of its math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DataFrame\n",
    "\n",
    "#### Working Directories & Relative Paths\n",
    "\n",
    "By now, you should have either downloaded the csv file \"CountyHealthData_2014-2015.csv\" from canvas, or saved your own data as a csv file. I've stored my copy in the same folder as this Jupyter Notebook. **NOTE:** make sure that your csv file is saved in the same working directory as your .ipynb notebook file that you will use. \n",
    "\n",
    "Remember that Jupyter Notebooks automatically set your working directory to the folder where the .ipynb is saved. You'll have to save the document at least once to set your directory, but once there you can use what's called relative file paths to access the files there.\n",
    "\n",
    "If a file is located in your working directory, its relative path is just the name of the file!\n",
    "\n",
    "#### Using the `pd.read_csv()` function\n",
    "\n",
    "`pd.read_csv` reads the tabular data from a Comma Separated Values (csv) file into a dataframe object that we'll define as `df`.\n",
    "\n",
    "To create our dataframe object we'll define our object `df` by executing the `pd.read_csv()`function on our data file by inserting the relative file path into the parathenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CountyHealthData_2014-2015.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7h/hb53jt7j2gx5nrf4vpy85q240000gn/T/ipykernel_41601/1499335158.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CountyHealthData_2014-2015.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CountyHealthData_2014-2015.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"CountyHealthData_2014-2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Our Dataframes\n",
    "\n",
    "#### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good first step in exploring our dataframe is to examine some of its basic attributes. Attributes contain **values** that provide  helpful information about the dataframe, that guide our interaction with the dataframe. In pandas, we access attributes with the following syntax:\n",
    "\n",
    "`<DataFrame name>.<attribute name>`\n",
    "\n",
    "We can use the `.shape` attribute to determine how many rows and columns (in that order) are available. The `.size` attribute gives us the number of cells in the dataframe (rows * columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size == 6109 * 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other useful attributes include:\n",
    "\n",
    "- `.columns` provides the column names for the Dataframe\n",
    "- `.dtypes` provides the pandas datatype for each column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'Region', 'Division', 'County', 'FIPS', 'GEOID', 'SMS Region',\n",
       "       'Year', 'Premature death', 'Poor or fair health',\n",
       "       'Poor physical health days', 'Poor mental health days',\n",
       "       'Low birthweight', 'Adult smoking', 'Adult obesity',\n",
       "       'Food environment index', 'Physical inactivity',\n",
       "       'Access to exercise opportunities', 'Excessive drinking',\n",
       "       'Alcohol-impaired driving deaths', 'Sexually transmitted infections',\n",
       "       'Teen births', 'Uninsured', 'Primary care physicians', 'Dentists',\n",
       "       'Mental health providers', 'Preventable hospital stays',\n",
       "       'Diabetic screening', 'Mammography screening', 'High school graduation',\n",
       "       'Some college', 'Unemployment', 'Children in poverty',\n",
       "       'Income inequality', 'Children in single-parent households',\n",
       "       'Social associations', 'Violent crime', 'Injury deaths',\n",
       "       'Air pollution - particulate matter', 'Drinking water violations',\n",
       "       'Severe housing problems', 'Driving alone to work',\n",
       "       'Long commute - driving alone', '2011 population estimate',\n",
       "       'Population that is not proficient in English',\n",
       "       'Population living in a rural area', 'Diabetes', 'HIV prevalence rate',\n",
       "       'Premature age-adjusted mortality', 'Infant mortality',\n",
       "       'Child mortality', 'Food insecurity', 'Limited access to healthy foods',\n",
       "       'Motor vehicle crash deaths', 'Drug poisoning deaths',\n",
       "       'Uninsured adults', 'Uninsured children', 'Health care costs',\n",
       "       'Could not see doctor due to cost', 'Other primary care providers',\n",
       "       'Median household income', 'Children eligible for free lunch',\n",
       "       'Homicide rate', 'Inadequate social support'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                            object\n",
       "Region                                           object\n",
       "Division                                         object\n",
       "County                                           object\n",
       "FIPS                                              int64\n",
       "GEOID                                             int64\n",
       "SMS Region                                       object\n",
       "Year                                             object\n",
       "Premature death                                 float64\n",
       "Poor or fair health                             float64\n",
       "Poor physical health days                       float64\n",
       "Poor mental health days                         float64\n",
       "Low birthweight                                 float64\n",
       "Adult smoking                                   float64\n",
       "Adult obesity                                   float64\n",
       "Food environment index                          float64\n",
       "Physical inactivity                             float64\n",
       "Access to exercise opportunities                float64\n",
       "Excessive drinking                              float64\n",
       "Alcohol-impaired driving deaths                 float64\n",
       "Sexually transmitted infections                 float64\n",
       "Teen births                                     float64\n",
       "Uninsured                                       float64\n",
       "Primary care physicians                         float64\n",
       "Dentists                                        float64\n",
       "Mental health providers                         float64\n",
       "Preventable hospital stays                      float64\n",
       "Diabetic screening                              float64\n",
       "Mammography screening                           float64\n",
       "High school graduation                          float64\n",
       "                                                 ...   \n",
       "Children in single-parent households            float64\n",
       "Social associations                             float64\n",
       "Violent crime                                   float64\n",
       "Injury deaths                                   float64\n",
       "Air pollution - particulate matter              float64\n",
       "Drinking water violations                       float64\n",
       "Severe housing problems                         float64\n",
       "Driving alone to work                           float64\n",
       "Long commute - driving alone                    float64\n",
       "2011 population estimate                          int64\n",
       "Population that is not proficient in English    float64\n",
       "Population living in a rural area               float64\n",
       "Diabetes                                        float64\n",
       "HIV prevalence rate                             float64\n",
       "Premature age-adjusted mortality                float64\n",
       "Infant mortality                                float64\n",
       "Child mortality                                 float64\n",
       "Food insecurity                                 float64\n",
       "Limited access to healthy foods                 float64\n",
       "Motor vehicle crash deaths                      float64\n",
       "Drug poisoning deaths                           float64\n",
       "Uninsured adults                                float64\n",
       "Uninsured children                              float64\n",
       "Health care costs                               float64\n",
       "Could not see doctor due to cost                float64\n",
       "Other primary care providers                    float64\n",
       "Median household income                           int64\n",
       "Children eligible for free lunch                float64\n",
       "Homicide rate                                   float64\n",
       "Inadequate social support                       float64\n",
       "Length: 64, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use attributes (`.loc` and `.iloc`) to interact with our dataframes on Friday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods\n",
    "\n",
    "Much of the functionality for working with dataframes comes in the form of methods. Methods are specialized functions that only work for a certain type of object, with the syntax:\n",
    "\n",
    "`<object name>.<method>()`\n",
    "\n",
    "We can look at the first 5 or last 5 rows in the dataset directly with the `.head()` and `.tail()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7h/hb53jt7j2gx5nrf4vpy85q240000gn/T/ipykernel_41601/964094849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7h/hb53jt7j2gx5nrf4vpy85q240000gn/T/ipykernel_41601/281403043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, our top and bottom rows aren't very representative, and we'd prefer to look at a random sample of rows to get a better sense of the data. We can do this with `.sample()` **Note** that we can supply the parameter `n` to specify how many rows we want to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7h/hb53jt7j2gx5nrf4vpy85q240000gn/T/ipykernel_41601/4055923431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series\n",
    "\n",
    "We can think of our dataframe as a collection rows and columns where each row represents an \"observation\"—sometimes referred to as a 'record'—and each column contains a specific type of information collected about each observation. \n",
    "\n",
    "In Pandas, our columns are stored as what's called 'Series' objects, and our dataframes can be thought of as named collections of series.\n",
    "\n",
    "We can extract a single column in a couple of ways:\n",
    "\n",
    "- bracket notation: `df[\"Region\"]` This is the most robust way to refer to Series\n",
    "\n",
    "- dot notation: `df.Region` This is simpler and easier to read but not always available\n",
    "\n",
    "\n",
    "In some cases, dot notation does not work! The most common situations are:\n",
    "\n",
    "- The column name has a space, or other irregularities \n",
    "- The column name is the same as an existing attribute or method (e.g., a column named \"shape\")\n",
    "\n",
    "For example, in our Public Health dataFrame, `df.Uninsured adults` doesn't work, because \"Uninsured adults\" is not understood as a single value, so instead we'd use `df[\"Uninsured adults\"]`\n",
    "\n",
    "Series have their own set of attributes and methods just like dataframes. Some attributes like `.dtypes` and `.shape` are available for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6109,)\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df.Region.shape)\n",
    "print(df.Region.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6109,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Region.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df.Region.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful methods for categorical variables is `.value_counts()` which provides a frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "South        2803\n",
       "Midwest      2038\n",
       "West          834\n",
       "Northeast     434\n",
       "Name: Region, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Region.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be used on top of other attributes or methods that return series. For example, the code below shows how frequently each data type appears in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    54\n",
       "object      6\n",
       "int64       4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for example, we might call up a value count of the series \"State\" to get a more granular sense of our dataframe's geographical dispersal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TX    469\n",
       "GA    318\n",
       "VA    266\n",
       "KY    240\n",
       "MO    229\n",
       "IL    204\n",
       "NC    200\n",
       "KS    199\n",
       "IA    198\n",
       "TN    190\n",
       "IN    184\n",
       "OH    176\n",
       "MN    174\n",
       "MI    164\n",
       "MS    163\n",
       "NE    157\n",
       "OK    154\n",
       "AR    150\n",
       "WI    144\n",
       "PA    134\n",
       "FL    134\n",
       "AL    134\n",
       "LA    128\n",
       "NY    124\n",
       "CO    119\n",
       "SD    117\n",
       "CA    114\n",
       "WV    110\n",
       "MT     92\n",
       "SC     92\n",
       "ND     92\n",
       "ID     84\n",
       "WA     78\n",
       "OR     67\n",
       "NM     64\n",
       "UT     54\n",
       "MD     48\n",
       "AK     46\n",
       "WY     46\n",
       "NJ     42\n",
       "NV     32\n",
       "ME     32\n",
       "AZ     30\n",
       "VT     28\n",
       "MA     28\n",
       "NH     20\n",
       "CT     16\n",
       "RI     10\n",
       "HI      8\n",
       "DE      6\n",
       "DC      1\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.State.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now open the `.ipyn` files you created last time: \n",
    "1. import pandas and numpy\n",
    "2. create a dataframe using `pd.read_csv`\n",
    "3. start explorng your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
